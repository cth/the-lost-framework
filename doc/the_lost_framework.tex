\documentclass{book}
% Creation of index
\usepackage{makeidx}
% Generation of hyperlink into a pdf file
\usepackage[colorlinks=true, urlcolor=blue,linktocpage=true]{hyperref} % Warning: Can be source of a compiled error if the \label \ref is not good 


\title{Lost API documentation}
\author{Lost Members}

\makeindex
\begin{document}
\maketitle


% Table of Contents
\addcontentsline{toc}{chapter}{Table of Contents}
\tableofcontents
%

\chapter{An introduction to the lost framework}

\section{The lost framework
}
The lost framework is a collection of utilities and models for
working with biological sequences written in PRISM/B-Prolog. 
The framework tries to unify all these bits and pieces and to
provide a way to integrate them.

\section{Obtaining a copy of the lost framework}

The lost framework can be obtained using \emph{git} if you have an account on the
\emph{mox} server. Assuming that you have \emph{git} installed on your
local machine, to get a copy you need to clone the central repository:
\begin{verbatim}
$ git clone ssh://your-username@mox.ruc.dk/var/git/lost.git
\end{verbatim}

It is also possible to clone the repository directly from mox if you
want to work there, rather than on your local machine. To do this,
just type 
\begin{verbatim}
$ git clone /var/git/lost.git
\end{verbatim}

In the following we will use \texttt{\$LOST} to refer to top-most
directory of your copy of the framework. 


\section{Configuring your copy of the lost framework}


After obtaining the lost framework, a little configuration is needed to get started.
You will need to edit the file \texttt{\$LOST/lost.pl}.
In the beginning of the file there are two important facts you may need to change,
\begin{verbatim}
lost_config(prism_command,'prism').
lost_config(lost_base_directory, '/change/to/local/lost/dir/').
lost_config(platform, windows_or_unix).
\end{verbatim}

The option \texttt{prism\_command} should point to a the main PRISM executable
binary. If it is in your  \emph{\$PATH} then you can usually leave it unchanged.\\
\texttt{lost\_base\_directory} should be the full path of the
directory (including trailing /) containing the \texttt{lost.pl}
file.  Note, that even on windows platforms you should use forward
slash rather than backslash in the path specification. The value of
\texttt{platform} should be either \texttt{windows} or \texttt{unix}. 

To get started you can examine and run \texttt{example.pl} which 
is located in the in the \texttt{\$LOST/scripts/} directory.

\subsection{File structure layout of the lost framework}

The lost framework is divided into several parts:
\begin{itemize}
\item \texttt{\$LOST/scripts/}: Contains scripts that run
  models. These scripts are just small Prolog programs. The scripts
  does not consult models directly, but instead use predicates that
  the framework provides.
\item \texttt{\$LOST/models/}: Contains all the biological sequence
  models. Each model is located in its own subdirectory of
  \texttt{\$TLOST/models/} the name of which is also used as name of
  the model.
\item \texttt{\$LOST/lib/}: Contains shared libraries used multiple
  models.
\item \texttt{\$LOST/data/}: Contains sequences and data to be used by
  the models. Annotations etc. generated by model invoked by the
  framework stored in this directory and given the extension
  \texttt{.gen} 
\item \texttt{\$LOST/tmp/}: Is used for temporary storage of files bt models.
\end{itemize}


\chapter{Creating lost models}

\section{Lost model conventions}\label{sec:lost_model_conventions}

Each model is located in its own subdirectory of the of the
\texttt{\$LOST/models/} directory, henceforth called \texttt{\$MODELS}. 
So for instance, the sample model called \texttt{sample\_model1} is located in
\texttt{\$MODELS/sample\_model1/}. In the following, we will refer to the directory 
where a particular model resides as \texttt{\$MODEL}.

Models are allowed to consult files with paths relative to the
\texttt{\$MODEL} directory, but should under normal circumstances
only directly consult file which are located in the 
\texttt{\$MODEL} directory or a subdirectory of it.
The exception to this is the file \texttt{\$LOST/lost.pl}. Consulting
this file gives access to all the shared APIs (See chapter \ref{chap:lost_shared_apis}).

To integrate into the framework each model must provide a file called
\texttt{interface.pl}, which must be located in the same directory as
the model. \texttt{interface.pl} can then implement various predefined
predicates which serves as an entry point of using the
model. 

The supported interface predicates which a model can provide are:
\begin{itemize}
\item \texttt{lost\_best\_annotation/3}.
\item \texttt{lost\_learn/3}
\end{itemize}

The general form of these predicates is that they take a list of
input files, a list of options and the name of an output file. They 
generally read the input files, do some processing and then write
a result to the output file. The type of processing depends on the
predicate. The predicate \texttt{lost\_best\_annotation/3} is meant to
be used when running the model in prediction mode, so for instance, it 
might produce a file containing the viterbi path for a given input
sequence. The predicate \texttt{lost\_learn} is meant to be used when 
training the model and the output file would usually be the learned
parameters of the trained model.

Models should declare the \emph{type} associated to the arguments of
these predicates. These include, 
\begin{itemize}
\item The formats of input files, see section
  \ref{sec:file_formats_declarations}.
\item The format of the output file, see section
  \ref{sec:file_formats_declarations}.
\item Options and default values for options, see section
  \ref{sec:option_declarations}.
\end{itemize}

%By convention models are expected to store switch probabilities the
%directory\texttt{\$MODEL/parameters/}. Switch parameter files should
%be given the extension \texttt{.prb}. However, depending on the type
%of model, this might not apply. The convention is not enforced in
%anyway and is only recommended practice.

\subsection{Model interface predicates}

This section describes predicates, that when implemented by 
the \texttt{interface.pl} provided by a model, allows the 
model provide functionalities that integrate into the general framework.

\noindent
\texttt{lost\_best\_annotation(+InputFileNames,+Options,+OutputFilename)}:
The framework calls this predicate to obtain a ``best annotation''
from the model. The model is free to provide this annotation in
any way it sees fit. It is the responsibility of the model to save the
annotation to \texttt{OutputFilename}, before the completion of
\texttt{lost\_best\_annotation}. 

\texttt{InputFileNames}: Is a list of filenames (with absolute paths),
each containing an input to the model. 

There is no restriction on the format of the files, but the model
should declare what file formats it expects.
Predicates to parse a wide range of fileformats are supplied 
in the \emph{io} API (see section \ref{sec:io}). 

\texttt{Options}: Is a list of facts on the form, where the functor
works as key and the first argument serves as the value of the
option, egg. \texttt{key(Value)}. This list is use to parameterize the model
in various ways. For convenience, option values can be checked an
extracted using the predicates \texttt{get\_option} (see section \ref{sec:interface}).

%Some options may be quite common and it is suggested to use the
%same functor name for such option. An incomplete list of these common
%option keys are,
%\begin{itemize}
%\item \texttt{parameter\_file}: Indicates that the model should use
% the switch probability associated with the \texttt{Value}. 
%\end{itemize}
The options used must be declared as described in section
\label{sec:option_declarations}.

\texttt{OutputFilename}: Full filename which the resulting ``best
annotation'' should be saved to. The model is expected to save
the resulting annotation to this file before the completion of 
\texttt{lost\_best\_annotation}. The \emph{io} API contains some
common predicates for saving annotations (see section \ref{sec:io}).

\noindent
\texttt{lost\_learn(+InputFileNames,+Options,+OutputFilename)}

This predicate is used for training models. The model is expected to 
save the result of the training session (e.g. a switch parameter file
or similar) to \texttt{OutputFilename}. 

\texttt{InputFileNames}: Is a list of filenames (with absolute paths),
each containing an input to the model. These are used for providing 
the traning data. 
There is no restriction on the format of the files, but the model
should declare what file formats it expects.
Predicates to parse a wide range of fileformats are supplied in
 the \emph{io} API (see section \ref{sec:io}). 

\texttt{Options}:Is a list of facts on the form, where the functor
works as key and the first argument serves as the value of the
option, egg. \texttt{key(Value)}. This list is use to parameterize the model
in various ways. For convenience, option values can be checked an
extracted using the predicates \texttt{get\_option} (see section \ref{sec:interface}).

\texttt{OutputFilename}: Full filename which the resulting switch
parameters or similar should be saved to. The model is expected to save
the result to this file before the completion of 
\texttt{lost\_learn}. The \emph{io} API contains some
common predicates for saving annotations (see section \ref{sec:io}).

\subsection{Declaration of options for interface predicates}
\label{sec:option_declarations}

Options to interface predicates should also be declared in the
\texttt{interface.pl} file. An option is declared by adding a 
fact \texttt{lost\_option/4} to the file:

\begin{verbatim}
lost_option(InterfaceGoal, OptionName, DefaultValue, Description).
\end{verbatim}

\begin{itemize}
\item \texttt{InterfaceGoal}: InterfaceGoal is one of
	\begin{itemize}
	  \item \texttt{lost\_best\_annotation}
	  \item \texttt{lost\_learn}
	\end{itemize}
\item \texttt{OptionName}: An atom for the name of key. This is the
  functor identifying this particular option.
\item \texttt{DefaultValue}: If the option is left unspecified then
it will take this value.
\item \texttt{Description}: A textual description of the purpose of 
the option. Should be in single quotes. 
\end{itemize}

\noindent
As example, consider an option declaration:
\begin{verbatim}
lost_option(lost_best_annotation,,default,'A parameter filename').
\end{verbatim}

In this declaration, we say that the goal
\texttt{lost\_best\_annotation} take the option
\texttt{parameter\_file}. If this option is not a member of the
\texttt{Options} list, then it will be added before calling 
\texttt{lost\_best\_annotation}. For instance, assume the model is
\texttt{sample\_model1}, then we might call
\begin{verbatim}
get_annotation_file(sample_models1,['/some/path/infile.seq'],[],FileOut),
\end{verbatim}
which will start a new PRISM process and invoke,
\begin{verbatim}
lost_best_annotation(['/some/path/infile.seq'],[parameter_file(default)],FileOut),
\end{verbatim}

\noindent
where the option \texttt{parameter\_file} has been inserted with the
default value. A default value is only inserted if the option is left
unspecified.


\subsection{Declaration of file formats for interface predicates}

%\paragraph{Note: This is preliminary thoughts and not yet implemented}

\subsubsection{Input file formats}

For each model interface predicate the format of input files and
output files should be declared as facts in the \texttt{interface.pl} file for the model.
To declare the format of the input files, a fact, 

\begin{verbatim}
lost_input_format(PredicateName, [ Format1, .., FormatN ]).
\end{verbatim}

\noindent
where \texttt{PredicateName} is the name of the predicate to which 
the declaration belong. The second argument is a list of format 
identifiers as described in chapter \ref{chap:file_formats}.
For instance, we may have a declaration,
\begin{verbatim}
lost_input(lost_best_annotation, 
    [ text(prolog(sequence(dna))), text(prolog(sequence(amino_acids)))]).
\end{verbatim}

The last entry of the list of formats may have the special star quantifier, which works 
similar to a kleene star: It states that the last entry is a placeholder for between zero or more entries of the specified type. For instance,
\begin{verbatim}
lost_input(lost_best_annotation, 
    [ text(prolog(sequence(dna))), star(text(prolog(sequence(dna))))]).
\end{verbatim}
\noindent
specifies that \texttt{lost\_best\_annotation} takes one or more input files of the type \texttt{text(prolog(sequence(dna)))}.

\subsubsection{Output file formats}

Contrary to the input file formats, the output file format can depend on the options given 
to the model. That means, the model may produce files in different output formats depending 
on the values of the options it is called with.

The output format is thus declared with a predicate, 
\begin{verbatim}
lost_output_format(PredicateName,Options, Format)
\end{verbatim}

\noindent
This predicate should specify the relation between a set of \texttt{Options} and a particular \texttt{Format} for the interface predicate \texttt{PredicateName}.
\texttt{Format} should unify to one of the formats described in chapter \ref{chap:file_formats}.

\chapter{Lost shared APIs}
\label{chap:lost_shared_apis}

To use the lost APIs, the file \texttt{\$LOST/lost.pl} must be consulted. To make the models
independent of the absolute path of the \texttt{\$LOST} directory, they should consult it with
a path relative to the model path (e.g. \texttt{:- ['../../lost.pl'].}).
 Then,
APIs, which are located in the \texttt{\$LOST/lib} directory
can be consulted using the goal, 
\begin{verbatim}
lost_include_api(+APIName)
\end{verbatim}

\noindent
where \texttt{APIName} is the name of a Prolog file located
in the \texttt{\$LOST/lib/} directory except the \texttt{.pl}
extension.

\section{The interface API: \texttt{interface}}

The API provides the interface to lost models following the
conventions described in section \ref{sec:lost_model_conventions}.

get\_annotation\_file(Model, Inputs, Options, Filename)

This API provides \texttt{get\_annotation\_file/4} which is used to
retrieve the best annotation generated by a specified model with
specified parameters and input sequences. If no such file currently
exists, then the model will be run (e.g. the
\texttt{lost\_best\_annotation/3} provided by the model will be
called).

The generated annotation files are named according to a convention. 
All annotation files will be placed in the \texttt{\$LOST/data/}
directory. 
The \texttt{Filename} is construed according to the following convention:
\begin{verbatim}
{Modelname}_{Id}.gen
\end{verbatim}

The first time an annotation is generated the file
\texttt{annotation.idx} will be created in this directory. This file
serves as a database to map filenames of the generated annotation
files to the (models ,inputs,probability parameters) that generated
the particular annotations. This database file contains Prolog facts 
on the form,
\begin{verbatim}
fileid(Id,Filename,Model,Options,InputFiles).
\end{verbatim}

The annotation index is automatically maintained by
\texttt{get\_annotation/4} and should normally not be edited by hand.

If annotation for a particular run of a model is not present then
\texttt{get\_annotation\_file/4} will start a new PRISM process 
that invokes the \texttt{lost\_best\_annotation} predicate provided
be the model \texttt{interface.pl} file. By the contract of model 
conventions, the model will generate the annotation and save it 
to the file indicated by the provided filename.

\section{Input-Output API: \texttt{io}}
\label{sec:io}

In this module (\texttt{io.pl}), severals predicates are defined to
manipulate \texttt{*.seq} files~:
\begin{itemize}
\item loading information from files that extracts from a file data information used as input of models (sequence annotation for example);
\item saving information into a file;
\item and maybe more. 
\end{itemize}

\subsection{Loading information from files}

\index{load\_annotation\_from\_file$\slash$ 4}
\begin{itemize}
\item \texttt{load\_annotation\_from\_file(++Type\_Info,++Options,++File,--Annotation)}:
Generate from \texttt{File} a sequence of \texttt{Annotation}. It is assumed that \texttt{File} is composed
of terms. \texttt{Type\_Info} is used to specify what format of information into file
\begin{itemize}
\item \texttt{sequence} means that information is stored into a list. For example, 
\begin{verbatim}
data(Key_Index,1,10,[a,t,c,c,c..]).
\end{verbatim}
\item \texttt{db} means that information is represented by a set of range that specified specific zone (coding region for example)
\begin{verbatim}
gb(Key_Index,1,10).
\end{verbatim}
\end{itemize}
For each \texttt{Type\_Info}, several options are available represented by the list \texttt{Options}. Options available
for \texttt{sequence}:
\begin{itemize}
\item $[]$ (default): data list is the $2^{th}$ argument of the terms and these lists of data are appended;
\item data\_position(Num) specified that data list is \texttt{Num}$^{th}$ argument of term;
\item \texttt{range(Min,Max)} extracts from the list of the complete annotation the sublist from position \texttt{Min} to
position \texttt{Max};
\item \texttt{all\_lists}: generate a list of each data list by term. Warning: \texttt{range(Min,Max)} is not support by this option.
\end{itemize}
File Example \texttt{toto.seq}:
\begin{verbatim}
data(Key_Index,1,5,[1,2,3,4,5]).
data(Key_Index,6,10,[6,7,8,9,10]).
data(Key_Index,11,15,[11,12,13,14,15]).
\end{verbatim}
Results of request are:
\begin{verbatim}
| ?- load_annotation_from_file(sequence,[data_position(4)],'toto.seq',R).
R = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] ?
| ?- load_annotation_from_file(sequence,[data_position(4),range(4,10)],'toto.seq',R).
R = [4,5,6,7,8,9,10] ?
load_annotation_from_file(sequence,[data_position(4),all_lists],'toto.seq',R).
R = [[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]] ?
\end{verbatim}

Options available for \texttt{db}:
\begin{itemize}
\item $[]$ (default): first and the second element of the term defined a range. A list of 0-1 
values is generated, 0 when you are outside ranges and 1 you are inside at least one;
\item \texttt{in\_db(Letter)} replaces the default value 1 by \texttt{Letter};
\item \texttt{out\_db(Letter)} replaces the default value 0 by \texttt{Letter};
\item \texttt{range\_position(Min,Max)} allows to specify the position argument number of a term of the minimal and maximal value
of term;
\item \texttt{range(Min,Max)} extracts from the list of the complete annotation the sublist from position \texttt{Min} to
position \texttt{Max};
\end{itemize}
File Example \texttt{toto.seq}:
\begin{verbatim}
gb(3,5).
gb(7,9).
gb(8,11). % Overlap ;)
\end{verbatim}
Results of request are:
\begin{verbatim}
| ?- load_annotation_from_file(db,[],'toto.seq',R).
R = [0,0,1,1,1,0,1,1,1,1,1] ?
| ?- load_annotation_from_file(db,[in_db(c),out_db(nc)],'toto.seq',R).
R =  [nc,nc,c,c,c,nc,c,c,c,c,c]?
| ?- load_annotation_from_file(db,[range(3,7)],R).
R = [1,1,1,0,1] ?
| ?- load_annotation_from_file(db,[in_db(c),out_db(nc),range(8,16)],'toto.seq',R).
R =  [c,c,c,nc,nc,nc,nc,nc]?
\end{verbatim}


\end{itemize}

\subsection{Saving information to files}

The io API also contains some predicates for saving sequences to a
file. 

\index{save\_annotation\_to\_sequence\_file$\slash$ 4}
\begin{itemize}
\item
  \texttt{save\_annotation\_to\_sequence\_file(+KeyIndex,+ChunkSize,+Annotation,+File)}: 
Saves the data in the list given by \texttt{Annotation} to the file
\texttt{File} in \emph{sequence} format which is number of Prolog facts, on
the form:
\begin{verbatim}
data(KeyIndex,1,5, [a,t,c,c,g]).
\end{verbatim}
The first argument \texttt{KeyIndex} is used as an identifier. \texttt{ChunkSize} is the
number of elements from \texttt{Annotation} to store with each
fact. The second and third argument of a stored fact, corresponds to
the start and end position in \texttt{Annotation}. The fourth
argument of the fact is a list containing the relevant elements of the
\texttt{Annotation} list. Note that if the the length of
\texttt{Annotation} is not a multiple of \texttt{ChunkSize}, then the
last fact stored will have a shorter range.
\end{itemize}

\section{The Stats API: \texttt{stats}}

In this module (\texttt{stats.pl}), several predicates are defined to automatically compute
frequencies, probabilities of occurrences of nucleotides, codons ... This computation
is based on a simple counting method given a simple input data. 

Variable \texttt{Data\_Type} is used to specify the type of the input data:
Data type available are:
\begin{itemize}
\item \texttt{nucleotid} where input data are composed of letter from $\{a,c,g,t\}$;
\item \texttt{codon} where a codon is represented by a list of three letters from $\{a,c,g,t\}$;
\item \texttt{animo\_acid} where input data are composed of letter from $\{a,c,d,e,f,g,h,$\\
$i,k,l,m,n,p,q,r,s,t,v,w,y\}$;
\item \texttt{length}. This type is used to compute frequencies and statistics about length of specific region of a genome. 
\end{itemize} 

Here is the description of main predicates of \texttt{stats.pl}
\begin{itemize}
\item stats(++Data\_Type,++Options,++Data,++Input\_Counting,--Result)\index{stats$\slash 5$} \\
\texttt{Data\_Type} setting define on which counting procedure is initialized. User must take care then
to give the right \texttt{Data}. For \{\texttt{nucleotid,codon,animo\_acid}\} data type, 
\texttt{Data} must be a Prolog list with the right element, For \texttt{length} data type,
\texttt{Data} must be a list of ranges represented by a list of two integer values ([Min,Max]).
Two options are available:
\begin{itemize}
\item \texttt{order(Num)} defines the size of the past stored to perform the counting
\item \texttt{past(List)} allows to give as input of the computation a previous past. This option is
useful to make connexion between two counting computations.
\end{itemize}
\texttt{Input\_Counting} is used as well to perform a counting computation on an input data divided
into a set of lists. By default, counting computation is initialized when is a variable \texttt{Input\_Counting}.
However, the counting can restart from \texttt{Input\_Counting} if this variable is unified to
the result of a previous result. Finally, \texttt{Result} has the following format:
\begin{verbatim}
[(Past1,[(Elt1,Count11),(Elt2,Count12),...]), 
 (Past2,[(Elt1,Count21),(Elt2,Count22),...]),
 ...]
\end{verbatim}
For example let consider this following data:
\begin{verbatim}
data('U00096',1,5,[a,g,c,t,t]).
data('U00096',6,10,[c,c,c,c,c]).
\end{verbatim}
Here is the result of this following request
\begin{verbatim}
| ?- stats(nucleotid,[],[a,g,c,t,t],_,R).
R = [([],[(a,1),(c,1),(g,1),(t,2)])] ?
| ?- stats(nucleotid,[order(1)],[a,g,c,t,t],_,R).
R = [([a],[(a,0),(c,0),(g,1),(t,0)]),
     ([c],[(a,0),(c,0),(g,0),(t,1)]),
     ([g],[(a,0),(c,1),(g,0),(t,0)]),
     ([t],[(a,0),(c,0),(g,0),(t,1)])]?
| ?- stats(nucleotid,[order(2)],[a,g,c,t,t],_,R1),
     stats(nucleotid,[order(2),past([t,t])],[c,c,c,c,c],R1,R).
R = [([a,a],[(a,0),(c,0),(g,0),(t,0)]),
     ([a,c],[(a,0),(c,0),(g,0),(t,1)]),
     ([a,g],[(a,0),(c,1),(g,0),(t,0)]),
     ([a,t],[(a,0),(c,0),(g,0),(t,0)]),
     ([c,a],[(a,0),(c,0),(g,0),(t,0)]),
     ([c,c],[(a,0),(c,3),(g,0),(t,1)]),
     ([c,g],[(a,0),(c,1),(g,0),(t,0)]),
     ([c,t],[(a,0),(c,0),(g,0),(t,1)]),
     ([g,a],[(a,0),(c,0),(g,0),(t,0)]),
     ([g,c],[(a,0),(c,0),(g,0),(t,1)]),
     ([g,g],[(a,0),(c,1),(g,0),(t,0)]),
     ([g,t],[(a,0),(c,0),(g,0),(t,1)]),
     ([t,a],[(a,0),(c,0),(g,0),(t,0)]),
     ([t,c],[(a,0),(c,0),(g,0),(t,1)]),
     ([t,g],[(a,0),(c,0),(g,0),(t,0)]),
     ([t,t],[(a,0),(c,1),(g,0),(t,0)]),
     ]?
\end{verbatim}
\item stats(++Data\_Type,++Options,++Data,++Input\_Counting,--Past,--Result)\index{stats$\slash 6$}
\texttt{stats$\slash 6$} computes exactly the same counting. This predicate allows only to record
into \texttt{Past} the last past of the computing. This predicate is usefull to compute 
statistics on a series of data input. For example, this following request
\begin{verbatim}
| ? - stats(nucleotid,[order(2)],[a,g,c,t,t],_,Past,R1),
      stats(nucleotid,[order(2),past(Past)],[c,c,c,c,c],R1,Past2,R).
Past = [t,t],
Past2 = [c,c],
R = ... ?
\end{verbatim}     
can be used to obtain counting information on the previous data.
\item normalize(++Data\_Type,++List\_Counting,--Probabilities)\index{normalize$\slash 3$}
From the result of a counting procedure, \texttt{normalize$\slash 3$} modified \texttt{List\_Counting}
to compute domains and probabilities distributions. 
\end{itemize} 
For example, here is the result of several requests:
\begin{verbatim}
| ?- stats(nucleotid,[],[a,g,c,t,t],_,R),
     normalize(nucleotid,R,S).
S = [([],([a,c,g,t],[0.2,0.2,0.2,0.4]))]
| ?- stats(nucleotid,[order(1)],[a,g,c,t,t],_,R),
     normalize(nucleotid,R,S).
S = [([a],([a,c,g,t],[0,0,1,0])),
     ([c],([a,c,g,t],[0,0,0,1])),
     ([g],([a,c,g,t],[0,1,0,0])),
     ([t],([a,c,g,t],[0,0,0,1]))] ?
\end{verbatim}



\chapter{Models}

Pre-defined models are introduced.  These models are used to build more complex models.

\section{Parsers of Biological Data}

To extract information from different Biological database, several parsers have been designed 
to parse report of analyses (Blast, Easygene and Genemark) and database (Genbank). 
These parsers generated a series of Prolog terms that can be used after that
input of different probabilistic models. \texttt{script\_parser.pl} collects different scripts to generate
different data files.

\subsection{Parser\_fna}

*.fna file of Genbank is composed of a complete genome in the FASTA format.
Parser\_fna permits to parse this *fna.file from Genbank and generate
list of terms. These terms store the genome into a Prolog list
composed of $\{a,c,g,t\}$. Two scripts are implemented:\\ 
\texttt{parser\_fna(++Name\_FNA\_File,++Name\_GBK\_File,++Options)}\index{parser\_fna$\slash$3} and \\
\texttt{parser\_fna(++Name\_FNA\_File,++Name\_GBK\_File,++Options,--OutputFile)}\index{parser\_fna$\slash$4}. \\
Note that *.gbk file is necessary as well. This file is used to automatically extract
genome information (Genbank key and size of genome).

Output format of the generated terms are:\\
\texttt{data(Genebank\_Key,Start,End,List\_of\_Data)}.
Option \texttt{list(Number)} can be used to divide the complete
genome into several lists with a length defined by the parameter
\texttt{Number}.
Example with the E.Coli K12 genome:
\begin{verbatim}
>gi|48994873|gb|U00096.2| Escherichia coli .....
AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGG.....
.....
\end{verbatim}
Result by default:
\begin{verbatim}
%>gi|48994873|gb|U00096.2| Escherichia coli ....
data('U00096',1,4639675,[a,g,c,t,t,t, ...]). 
\end{verbatim}
Result when \texttt{list(280)} option is used
\begin{verbatim}
%>gi|48994873|gb|U00096.2| Escherichia .....
data('U00096',1,280,[a,g,c,t,...]).
data('U00096',281,560,[c,c,c,...]).
....
\end{verbatim}

\subsection{Parser\_ptt}

*.ptt file of Genbank is composed of information about known or predicted
genes in a genome. Parser\_ptt parses this *.ptt file from Genbank and generate
list of terms. Two scripts are implemented:\\ 
\texttt{parser\_ptt(++Name\_PTT\_File)}\index{parser\_ptt$\slash$1} and \\
\texttt{parser\_ptt(++Name\_PTT\_File,,--OutputFile)}\index{parser\_ptt$\slash$2}.

Output format of the generated terms are:\\
\texttt{gb(Genebank\_Key,Start,End)}.

\subsection{Parser\_Easygene}

This parser allows to generate from the \href{http://servers.binf.ku.dk/easygene/1.2/gff_output.html}{GFF format} 
of Easygene prediction several Prolog terms with the following format:
\texttt{eg(Left,Right,Dir,Frame,[])}.

Two scripts are implemented:\\ 
\texttt{parser\_easygene(++Report\_Name)}\index{parser\_easygene$\slash$1} and \\
\texttt{parser\_easygene(++Report\_Name,--OutputFile)}\index{parser\_easygene$\slash$2}.

\subsection{Parser\_Genemark}

This parser allows to generate from a report of Genemark.HMM 
of Easygene prediction several Prolog terms with the following format:
\texttt{gm(Left,Right,Dir,Frame,[])}. 
Genemark report of prediction coordinates is parsed.

Two scripts are implemented:\\ 
\texttt{parser\_genemark(++Report\_Name)}\index{parser\_genemark$\slash$1} and \\
\texttt{parser\_genemark(++Report\_Name,--OutputFile)}\index{parser\_genemark$\slash$2}.

\subsection{Parser\_Blast}

This parser translated into Prolog terms the XML report of Tblastn. The parser a fact for
each hits detected in the XML report.


\section{Models for measurement and statistical reports}

\subsection{accuracy\_report}

The model \texttt{accuracy\_report} can be used the produce a report of
various measures of the accuracy of particular gene predictions
compared with a golden standard such a genebank. 

To use the the model, you need to call
\texttt{get\_annotation\_file/4} with the following arguments,
\begin{verbatim}
get_annotation_file(accuracy_report,
		    [ReferenceFile,PredictionFile],
		    [
		     option(reference_functor,RefFunctor),
		     option(prediction_functor,PredFunctor),
		     option(start,StartPos),
		     option(end,EndPos)
		    ],
		    OutputFile),
\end{verbatim}

\texttt{ReferenceFile} must be the full path to a file with facts
representing the ``correct predictions''.  
\texttt{PredictionFile} must be the full path to a file with facts
representing the predictions. Both files must be a a \texttt{db} type 
format, with facts on the following form,
\begin{verbatim}
functor(To, From, Strand, ReadingFrame, Name).
\end{verbatim}

Each such fact represent a prediction in the \texttt{PredictionFile} or
correct gene in the in \texttt{ReferenceFile}. 
The \texttt{functor} is a any given functor, but the
\texttt{ReferenceFile} and the \texttt{PredictionFile} should use
different functors. The \emph{To} argument represents the position in
the genome where the prediction begins (inclusive) and the
\texttt{From} argument represents the end position of the prediction
\texttt{ReadingFrame} is a integer in the range $\{1,2,3\}$
\texttt{Strand} is either \texttt{+} for the forward strand or
    \texttt{-} for the reverse strand. 

\texttt{get\_annotation\_file} for the \texttt{accuracy\_report} model
must be called with four mandatory options:
\begin{itemize}
\item \texttt{reference\_functor}: The functor used in the \texttt{ReferenceFile}
\item \texttt{prediction\_functor}: The functor used in the
  \texttt{PredictionFile}
\item \texttt{start}: An integer corresponding to the beginning of the range on which accuracy
  should be measured.
\item \texttt{end}: An integer corresponding to the end of the range
  (inclusive) on which accuracy should be measured.
\end{itemize}

\section{Prediction/Gene filter models}

Common for these models is that they all take files in the
\texttt{text(prolog(ranges(\_)))} format and produce output in 
the same format. Usually, the output will be a subset of the entries
from the input file.

\subsection{longest\_predication\_per\_stop\_codon}

Given an input file with gene predictions, this model selects for each
stop codon the longest matching prediction. Only the longest
prediction for each stop coden will be written to the output file.

For the goal \texttt{lost\_best\_annotation/3}, the following files
and options are expected:
\begin{itemize}
\item Input files: \texttt{text(prolog(ranges(gene)))}
\item Output file: \texttt{text(prolog(ranges(gene)))}
\end{itemize}

The model only takes one option, \texttt{file\_functor}, which is 
used to set the functor to identify the gene predictions in the input
file. If the input file contains only facts with the same functor the 
default value \texttt{auto} can be used and the model will infer the 
functor automatically.

\subsection{best\_prediction\_per\_stop\_codon}

Given an input file with gene predictions this model selects, for each
stop codon, the prediction with the highest score and write such
predictions to the output file. The score is for each prediction is
assumed to be present the \texttt{Extra} list argument of the
prediction facts in the input file. 

For the goal \texttt{lost\_best\_annotation/3}, the following files
and options are expected:
\begin{itemize}
\item Input files: \texttt{text(prolog(ranges(gene)))}
\item Output file: \texttt{text(prolog(ranges(gene)))}
\end{itemize}

The model only takes two option:

\begin{itemize} 
\item \texttt{file\_functor}: Is used to set the functor to
  identify the gene predictions in the input file. If the input file
  contains only facts with the same functor the default value
  \texttt{auto} can be used and the model will infer the functor
  automatically.
\item \texttt{score\_functor}: Is used to specify how the score is
  represented in the \texttt{Extra} list. For instance, if the Extra
  list looks like \verb|[...,score(0.75),..]|,  then the
  \texttt{score\_functor} option should be set to \texttt{score}.
  The argument of the score functor (\texttt{0.75} in the example)
  should be a number or at least something comparable with the
  standard less-than-or-equal-to Prolog operators.
\end{itemize}

\section{Model that integrate other programs}

\subsection{Genemark}

To be documented...

\subsection{Glimmer3}

To be documented...

\section{Various models}

\subsection{hard\_to\_find\_genes}

The model \texttt{hard\_to\_find\_genes} ranks a given set of genes
according to how many genefinders that find the gene.

The input to the model is a list of files, of which the first element
is taken to the \emph{golden standard} - a set of \emph{true} genes.
The rest of the files in the input file list are files that contain
gene predictions of various genefinders (one genefinder per input
file). All the files are expected to be in the
\texttt{text(prolog(ranges(gene)))} format.

For each gene in the \emph{golden standard} file, the model checks 
which of the gene finders predicted this gene. 

To be continued... Monday.


\chapter{File formats}

The chapter documents the different types of file formats used in the
lost framework. The naming of file formats follow a simple scheme
using  nested Prolog functors where the outermost functor is the most
general and the innermost is the most specific description of the file
format. For instance, consider the naming for a DNA sequence expressed
as a Prolog file,
\begin{verbatim}
text(prolog(sequence(dna)))
\end{verbatim} 

The outermost functor \texttt{text} specifies that the file is a text
file, and the next functor \texttt{prolog} says that the text file
contains Prolog code. The next one, \texttt{sequence}, specifies the
type of data (sequence data) we expect to be expressed in the prolog
facts finally, the innermost functor \texttt{dna} specifies the type
of sequence that we are dealing with.

\section{\texttt{text(prolog(\_))}}

\texttt{text(prolog(\_))} formats contain Prolog facts. The functor and
arity of those facts cannot be determined by knowing that it is
\texttt{text(prolog(\_))}, but needs specification using further embbed
functors.

\subsection{\texttt{text(prolog(sequence(\_)))}}

This format should be specified for sequence data expressed as prolog
facts. For instance, a file of this format may contain facts like the
ones below, which specifies the alphabet, 
\begin{verbatim}
data(alphabet,1,10, [a,b,c,d,e,f,g,h,i,j]).
data(alphabet,11,20],[k,l,m,n,o,p,q,r,s,t]).
data(alphabet,21,27,[u,v,w,x,y,z]).
\end{verbatim}

\noindent
The form of these facts are, 
\begin{verbatim}
functor(Identifier,To,From,SequenceElementList).
\end{verbatim}

\noindent
The format does not dictate the \texttt{functor} of the facts
(e.g. \texttt{data}), nor the size of the data list in the fourth
argument. However, the range expressed by \texttt{To} and
\texttt{From} should correspond to the numer of elements
in \texttt{SequenceElementList}.

\subsubsection{\texttt{text(prolog(sequence(dna)))}}

Like the above format but restricts the alphabet of the data elements
in the \texttt{SequenceElementList} to the set \texttt{\{a,g,c,t\}}.

\subsubsection{\texttt{text(prolog(sequence(rna)))}}

Like the above format but restricts the alphabet of the data elements
in the \texttt{SequenceElementList} to the set \texttt{\{a,g,c,u\}}.

\subsubsection{\texttt{text(prolog(sequence(amino\_acids)))}}

Like the above format but restricts the alphabet of the data elements
in the \texttt{SequenceElementList} to the set
\texttt{\{a,c,d,e,f,g,h,i,k,l,m,n,p,q,r,s,t,v,w,y\}}.

\subsection{\texttt{text(prolog(ranges(\_)))}} 

The format consists of Prolog facts, each of which contain an
annotation for a particular range of some sequence

\begin{verbatim}
F =.. [ Functor, LeftEnd, RightEnd | _ ]
\end{verbatim}

The functor may vary depending on the type of annotation but is
expected to be same within a file. The first two arguments,
\texttt{LeftEnd} and \texttt{RightEnd} are positive integers which specifies 
the range relative to the sequence. Both are inclusive.

\subsubsection{\texttt{text(prolog(ranges(gene)))}} 

The format consists of Prolog facts, each of which contain an
gene annotation for a particular range of some DNA sequence
 (all facts refer to the same sequence).

The facts are on the form, 
\begin{verbatim}
functor(LeftEnd,RightEnd,Strand,Frame,ExtraList).
\end{verbatim}

The functor may vary depending on the type of annotation but is
expected to be same within a file. The first two arguments,
\texttt{Start} and \texttt{End} are positive integers which specifies 
the range of the annotation relative to the DNA sequence. The
\texttt{Strand} argument is \texttt{+} for the forward strand
or\texttt{-} for the reverse strand. The \texttt{Frame} argument
is one of \texttt{\{1,2,3\}}. The final argument, \texttt{ExtraList}
is a list possibly containing extra information.

\subsection{\texttt{text(prolog(prism\_switches))}}

This is the format used by PRISM to save and load parameter files.

\subsection{\texttt{text(ptt)}}

TODO ptt files

\subsection{\texttt{text(easygene\_report)}}

TODO ptt files

\subsection{\texttt{text(fasta(SequenceType)}}

A sequence in FASTA format begins with a single-line description,
followed by lines of sequence data. The description line is
distinguished from the sequence data by a greater-than (">") symbol in
the first column. The word following the ">" symbol is the identifier
of the sequence, and the rest of the line is the description (both are
optional). There should be no space between the ">" and the first
letter of the identifier. It is recommended that all lines of text be
shorter than 80 characters. The sequence ends if another line starting
with a ">" appears; this indicates the start of another sequence. 

The format identifier \texttt{text(fasta(\_))} is used to refer to any
type of file in FASTA format, but we distinguish between different 
subtypes with \texttt{SequenceType}. A ground value for
\texttt{SequenceType} may be one of the following:

\begin{itemize}
\item \texttt{fasta}: Specifies generic fasta format. This is the same
  as specifying \texttt{text(fasta(\_))}.
\item \texttt{fna}: fasta nucleic acid. 
\item \texttt{ffn}: FASTA nucleotide coding regions. Contains coding
  regions for a genome.
\item \texttt{ffa}: fasta amino acid.
\end{itemize}

\chapter{Notes and stuff}

\section{Feature wish list}

\begin{itemize}

\item Division of models into models (probabilistic models) and nodes
  (which are just data processing).

\item 

\item Document gene database file format and make sure that all models
  adhere to this format.

\item Option, input and output formats for all models. (Matthieu, Christian)

\item Data outside git (Christian)

\item Models should \texttt{lost\_tmp\_directory} for intermediary
  files. 

\item Document all of undocumented models. (Matthieu, Christian)

\end{itemize}

Some things that we have discussed, but  decided not to do
\begin{itemize}
\item Do something to avoid multiple declaration of lost\_include\_api
 everywhere... (Matthieu).
\end{itemize}

\printindex

\end{document}
