\documentclass{book}
% Creation of index
\usepackage{makeidx}
% Generation of hyperlink into a pdf file
\usepackage[colorlinks=true, urlcolor=blue,linktocpage=true]{hyperref} % Warning: Can be source of a compiled error if the \label \ref is not good
\usepackage{pldoc}

\title{Lost API documentation}
\author{Lost Members}

%\makeindex
\begin{document}
\maketitle


% Table of Contents
\addcontentsline{toc}{chapter}{Table of Contents}
\tableofcontents
%

\chapter{An introduction to the lost framework}

\section{The lost framework}

The lost framework is a collection of utilities and models for
working with biological sequences written in PRISM/B-Prolog. 
The framework tries to unify all these bits and pieces and to
provide a way to integrate them.

\section{Obtaining a copy of the lost framework}

The lost framework can be obtained using \emph{git} if you have an account on the
\emph{mox} server. Assuming that you have \emph{git} installed on your
local machine, to get a copy you need to clone the central repository:
\begin{verbatim}
$ git clone ssh://your-username@mox.ruc.dk/var/git/lost.git
\end{verbatim}

It is also possible to clone the repository directly from mox if you
want to work there, rather than on your local machine. To do this,
just type 
\begin{verbatim}
$ git clone /var/git/lost.git
\end{verbatim}

In the following we will use \texttt{\$LOST} to refer to top-most
directory of your copy of the framework. 

\section{Configuring your copy of the lost framework}


After obtaining the lost framework, a little configuration is needed to get started.
You will need to edit the file \texttt{\$LOST/lost.pl}.
In the beginning of the file there are two important facts you may need to change,
\begin{verbatim}
lost_config(prism_command,'prism').
lost_config(lost_base_directory, '/change/to/local/lost/dir/').
lost_config(platform, windows_or_unix).
\end{verbatim}

The option \texttt{prism\_command} should point to a the main PRISM executable
binary. If it is in your  \emph{\$PATH} then you can usually leave it unchanged.\\
\texttt{lost\_base\_directory} should be the full path of the
directory (including trailing /) containing the \texttt{lost.pl}
file.  Note, that even on windows platforms you should use forward
slash rather than backslash in the path specification. The value of
\texttt{platform} should be either \texttt{windows} or \texttt{unix}. 

To get started you can examine and run \texttt{example.pl} which 
is located in the in the \texttt{\$LOST/scripts/} directory.

\subsection{File structure layout of the lost framework}

The lost framework is divided into several parts:
\begin{itemize}
\item \texttt{\$LOST/scripts/}: Contains scripts that run
  models. These scripts are just small Prolog programs. The scripts
  does not consult models directly, but instead use predicates that
  the framework provides.
\item \texttt{\$LOST/models/}: Contains all the biological sequence
  models. Each model is located in its own subdirectory of
  \texttt{\$TLOST/models/} the name of which is also used as name of
  the model.
\item \texttt{\$LOST/lib/}: Contains shared libraries used multiple
  models.
\item \texttt{\$LOST/data/}: Contains sequences and data to be used by
  the models. Annotations etc. generated by model invoked by the
  framework stored in this directory and given the extension
  \texttt{.gen} 
\item \texttt{\$LOST/tmp/}: Is used for temporary storage of files bt models.
\end{itemize}


\chapter{Creating lost models}

\section{Lost model conventions}\label{sec:lostmodelconventions}

Each model is located in its own subdirectory of the 
\texttt{\$LOST/models/} directory, henceforth called \texttt{\$MODELS}. 
So for instance, the sample model called \texttt{sample\_model1} is located in
\texttt{\$MODELS/sample\_model1/}. In the following, we will refer to the directory 
where a particular model resides as \texttt{\$MODEL}.

Models are allowed to consult files with paths relative to the
\texttt{\$MODEL} directory, but should under normal circumstances
only directly consult file which are located in the 
\texttt{\$MODEL} directory or a subdirectory of it.
The exception to this is the file \texttt{\$LOST/lost.pl}. Consulting
this file gives access to all the shared APIs (See chapter \ref{chap:lostsharedapis}).

To integrate into the framework each model must provide a file called
\texttt{interface.pl}, which must be located in the same directory as
the model. In the file \texttt{interface.pl}, one or more interface
predicates are defined.  These predicates serve as entry points of
using the model. 

\subsection{Model interface predicates}

This section describes predicates, that when implemented in 
the \texttt{interface.pl} file provided by a model, allows the 
model provide functionalities that integrate into the general framework.

For common tasks these predicate are named according to the
following convention:
\begin{itemize}
\item \texttt{annotate/3}: Do inference with the model and produce a
  "annotation" as output. The annotation take different forms depending on context.
\item \texttt{train/3}: Training the model on the input data and save
  a switch file or similar as output.
\item \texttt{generate/3}: Generate some data using the model.
\end{itemize}

It is possible to use the other predicate names than these, but it is 
\emph{strongly} recommended to use these names whenever it makes
sense.

The general form of these predicates is that they take a list of
input files, a list of options and the name of an output file. They 
generally read the input files, do some processing and then write
a result to the output file. The type of processing depends on the
predicate. The predicate \texttt{annotate/3} is meant to
be used when running the model in prediction mode, so for instance, it 
might produce a file containing the viterbi path for a given input
sequence. The predicate \texttt{train/3} is meant to be used when 
training the model and the output file would usually be the learned
parameters of the trained model. With the \texttt{generate/3}
predicate, the model is supposed to be used in a generative fashion.

Models should declare the \emph{type} associated to the arguments of
these predicates. These declarations include
\begin{itemize}
\item The formats of input files, see section
  \ref{sec:fileformatsdeclarations}.
\item The format of the output file, see section
  \ref{sec:fileformatsdeclarations}.
\item Options and default values for options, see section
  \ref{sec:optiondeclarations}.
\item Optionally, a set of possible values any declared option.
\end{itemize}

%By convention models are expected to store switch probabilities the
%directory\texttt{\$MODEL/parameters/}. Switch parameter files should
%be given the extension \texttt{.prb}. However, depending on the type
%of model, this might not apply. The convention is not enforced in
%anyway and is only recommended practice.

Interface predicates have the following form,

\begin{verbatim}
predicate_name(+InputFileNames,+Options,+OutputFilename)
\end{verbatim}

The predicate takes the following arguments:
\begin{itemize}

\item \texttt{InputFileNames}: Is a list of filenames (with absolute paths),
  each containing an input to the model. 
  There is no restriction on the format of the files, but the model
  should declare what file formats it expects.
  Predicates to parse a wide range of fileformats are supplied 
  in the \emph{io} API (see section \ref{sec:io}). 

\item \texttt{Options}: Is a list of facts on the form, where the functor
  works as key and the first argument serves as the value of the
  option, egg. \texttt{key(Value)}. This list is used to parameterize the model
  in various ways. To check the value of a given option, the predicate
  \texttt{get\_option} (see section \ref{sec:interface}) should be used.
  The options must be declared as described in section
  \label{sec:optiondeclarations}.

\item \texttt{OutputFilename}: Full filename which the result should be saved to. The model is expected to save
  the resulting annotation to this file before the completion of 
  \texttt{annotate}. The \emph{io} API contains some
  common predicates for saving annotations (see section \ref{sec:io}).
\end{itemize}

Depending the the \texttt{predicate\_name} the predicates will do
conceptually different things, but there is a common pattern:
The model reads a processes the files given \texttt{InputFileNames}.
It is then the responsibility of the predicate to save the
annotation to \texttt{OutputFilename}. If the model for some
reason is unable to write the annotation to \texttt{OutputFilename},
then it should \texttt{throw} an exception.

\subsection{Declaration of options for interface predicates}
\label{sec:optiondeclarations}

Options to interface predicates should be declared in the
\texttt{interface.pl} file. An option is declared by adding a 
fact 
\begin{verbatim}
lost_option(+InterfaceGoal,+OptionName,+DefaultValue,+Description).
\end{verbatim}

\begin{itemize}
\item \texttt{InterfaceGoal}: InterfaceGoal is the functor name of defined interface predicate.
\item \texttt{OptionName}: An atom for the name of key. This is the
  functor identifying this particular option.
\item \texttt{DefaultValue}: If the option is left unspecified then
it will take this value.
\item \texttt{Description}: A textual description of the purpose of 
the option. Should be in single quotes. 
\end{itemize}

\noindent
As example, consider an option declaration:
\begin{verbatim}
lost_option(annotate,debug,no,'Enable/disable debug prints').
\end{verbatim}

In this declaration, we state that the goal
\texttt{annotate} take the option
\texttt{debug}. If this option is not a member of the
\texttt{Options} list, then it will be added with the default value \texttt{no} before 
\texttt{annotate} is called by the framework. 

For instance, assuming the model is called \texttt{my\_model}, it
might be called from a script with
\begin{verbatim}
get_annotation_file(my_model,['/some/path/infile'],[],FileOut),
\end{verbatim}
which will start a new PRISM process and invoke 
\begin{verbatim}
annotate(['/some/path/infile'],[debug(no)],FileOut),
\end{verbatim}
in \texttt{\$MODELS/my\_model/interface.pl}.
Note that the option \texttt{debug} has been inserted with the
default value. A default value is only inserted if the option is left
unspecified.

\subsubsection{Declaring option values}

If the values of an option can be enumerated, then the model should
provide a declaration of by defining a predicate, 
\begin{verbatim}
lost_option_values(+Predicate,+OptionName,-ValuesList).
\end{verbatim}

In our example above, the option \texttt{debug} might have two
possible values, \texttt{no} and \texttt{yes}, so a declaration might
look like, 
\begin{verbatim}
lost_option_values(annotate, debug, [yes,no]).
\end{verbatim}

\subsubsection{Option checking}

When a model is invoked by the framework, options are checked before 
invoking the model. If a model is called with an option which has not
been declared by the model, then a warning will be issued. Similarly, 
if a declared option for a predicate also has a
\texttt{lost\_option\_values} declaration and the a predicate is called
with the option set to value which is not part of the declaration, the a warning is issued. 

\subsection{Declaration of file formats for interface predicates}

%\paragraph{Note: This is preliminary thoughts and not yet implemented}

\subsubsection{Input file formats}

For each model interface predicate the format of input files and
output files should be declared as facts in the \texttt{interface.pl} file for the model.
To declare the format of the input files, a fact, 

\begin{verbatim}
lost_input_format(PredicateName, [ Format1, .., FormatN ]).
\end{verbatim}

\noindent
where \texttt{PredicateName} is the name of the predicate to which 
the declaration belong. The second argument is a list of format 
identifiers as described in chapter \ref{chap:fileformats}.
For instance, we may have a declaration,
\begin{verbatim}
lost_input(annotate, 
    [ text(prolog(sequence(dna))), text(prolog(sequence(amino_acids)))]).
\end{verbatim}

The last entry of the list of formats may have the special star quantifier, which works 
similar to a kleene star: It states that the last entry is a placeholder for between zero or more entries of the specified type. For instance,
\begin{verbatim}
lost_input(annotate, 
    [ text(prolog(sequence(dna))), star(text(prolog(sequence(dna))))]).
\end{verbatim}
\noindent
specifies that \texttt{annotate} takes one or more input files of the type \texttt{text(prolog(sequence(dna)))}.

\subsubsection{Output file formats}

Contrary to the input file formats, the output file format can depend on the options given 
to the model. That means, the model may produce files in different output formats depending 
on the values of the options it is called with.

The output format is thus declared with a predicate, 
\begin{verbatim}
lost_output_format(PredicateName,Options, Format)
\end{verbatim}

\noindent
This predicate should specify the relation between a set of \texttt{Options} and a particular \texttt{Format} for the interface predicate \texttt{PredicateName}.
\texttt{Format} should unify to one of the formats described in
chapter \ref{chap:fileformats}.

\subsubsection{Checking of file formats}

The framework checks that file formats are declared according to the 
scheme described above. If a model neglects to declare file formats or
declares them wrongly, then a warning will be issued.

\chapter{Lost shared APIs}
\label{chap:lostsharedapis}

To use the lost APIs, the file \texttt{\$LOST/lost.pl} must be consulted. To make the models
independent of the absolute path of the \texttt{\$LOST} directory, they should consult it with
a path relative to the model path (e.g. \texttt{:- ['../../lost.pl'].}).
 Then,
APIs, which are located in the \texttt{\$LOST/lib} directory
can be consulted using the goal, 
\begin{verbatim}
lost_include_api(+APIName)
\end{verbatim}

\noindent
where \texttt{APIName} is the name of a Prolog file located
in the \texttt{\$LOST/lib/} directory except the \texttt{.pl}
extension.

\section{The interface API: \texttt{interface}}

The API provides the interface to lost models following the
conventions described in section \ref{sec:lostmodelconventions}.

Running a model is done using the goal \texttt{run\_model}
\begin{verbatim}
run_model(Model,annotate(InputFiles,Options,OutputFile)
\end{verbatim}

%The predicate,
%\begin{verbatim}
%get_annotation_file(Model, Inputs, Options, OutputFile)
%\end{verbatim}

In this case we run the models \texttt{annotate} goal. 
This is used to retrieve the annotation generated by a specified
\texttt{Model} invoked with the specified \texttt{InputFiles} and
\texttt{Options}. \texttt{InputFiles} is a list of file names containing 
input for the model. \texttt{Options} is a list of facts on the form
\texttt{key(Value)}, where \texttt{key} is the name of an
option and \texttt{Value} is a concrete value.
As a consequence of calling this predicate the output from the model is written to the file
\texttt{OutputFile}. If the model has been previously invoked with exactly
the same \texttt{InputFiles} and \texttt{Options} , then
\texttt{OutputFile} will unify with the outcome of the previous
invokation. In this way, the results of running a model are cached.

The generated annotation files are named according to a convention, where 
all annotation files will be placed in the \texttt{\$LOST/data/}
directory and the \texttt{Filename} is construed according to the following convention:
\begin{verbatim}
{Model}_{GoalFunctor}_{Id}.gen
\end{verbatim}

The first time a model \texttt{OutputFile} is generated, the file
\texttt{annotation.idx} will be created in \texttt{\$LOST/data/}. This file
serves as a database to map the filename of a generated annotation
file to the model, input files and options that generated
the particular annotation. This database file contains Prolog facts 
of the form
\begin{verbatim}
fileid(Id,Filename,Model,Goal,Options,InputFiles).
\end{verbatim}

The annotation index is automatically maintained by
\texttt{get\_annotation\_file/4} and should not be edited by hand.

If an annotation for a particular run of a model is not present then
\texttt{get\_annotation\_file/4} will start a new PRISM process 
that invokes the \texttt{annotate} predicate provided
be the model \texttt{interface.pl} file. By the contract of model 
conventions, the model will generate the annotation and save it 
to the file indicated by the provided filename.

\subsection{Moving generated files around}

Once a file has been generated, you may wish the move or rename the
file. Doing this using normal system commands will fail to the update 
the annotation index and as result the file may be regenerated, even 
if it was already generated once.  Instead, you should use

\begin{verbatim}
move_data_file(+OldFilename, +NewFilename)
\end{verbatim}
\noindent
This predicate makes sure that the annotation index is updated accordingly.

\section{Input-Output API: \texttt{io}}
\label{sec:io}

In this module (\texttt{io.pl}), several predicates are defined to
manipulate \texttt{*.seq} files~:
\begin{itemize}
\item loading information from files that extracts from a file data
  information used as input of models (sequence annotation for
  example);
\item saving information into a file;
\item and maybe more. 
\end{itemize}

\subsection{Loading information from files}

\index{load\_annotation\_from\_file$\slash$ 4}
\begin{itemize}
\item \texttt{load\_annotation\_from\_file(++Type\_Info,++Options,++File,--Annotation)}:
Generate from \texttt{File} a sequence of \texttt{Annotation}. It is assumed that \texttt{File} is composed
of terms. \texttt{Type\_Info} is used to specify what format of information into file
\begin{itemize}
\item \texttt{sequence} means that information is stored into a list. For example, 
\begin{verbatim}
data(Key_Index,1,10,[a,t,c,c,c..]).
\end{verbatim}
\item \texttt{db} means that information is represented by a set of range that specified specific zone (coding region for example)
\begin{verbatim}
gb(Key_Index,1,10).
\end{verbatim}
\end{itemize}
For each \texttt{Type\_Info}, several options are available represented by the list \texttt{Options}. Options available
for \texttt{sequence}:
\begin{itemize}
\item $[]$ (default): data list is the $2^{th}$ argument of the terms and these lists of data are appended;
\item data\_position(Num) specified that data list is \texttt{Num}$^{th}$ argument of term;
\item \texttt{range(Min,Max)} extracts from the list of the complete annotation the sublist from position \texttt{Min} to
position \texttt{Max};
\item \texttt{all\_lists}: generate a list of each data list by term. Warning: \texttt{range(Min,Max)} is not support by this option.
\end{itemize}
File Example \texttt{toto.seq}:
\begin{verbatim}
data(Key_Index,1,5,[1,2,3,4,5]).
data(Key_Index,6,10,[6,7,8,9,10]).
data(Key_Index,11,15,[11,12,13,14,15]).
\end{verbatim}
Results of request are:
\begin{verbatim}
| ?- load_annotation_from_file(sequence,[data_position(4)],'toto.seq',R).
R = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] ?
| ?- load_annotation_from_file(sequence,[data_position(4),range(4,10)],'toto.seq',R).
R = [4,5,6,7,8,9,10] ?
load_annotation_from_file(sequence,[data_position(4),all_lists],'toto.seq',R).
R = [[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]] ?
\end{verbatim}

Options available for \texttt{db}:
\begin{itemize}
\item $[]$ (default): first and the second element of the term defined a range. A list of 0-1 
values is generated, 0 when you are outside ranges and 1 you are inside at least one;
\item \texttt{in\_db(Letter)} replaces the default value 1 by \texttt{Letter};
\item \texttt{out\_db(Letter)} replaces the default value 0 by \texttt{Letter};
\item \texttt{range\_position(Min,Max)} allows to specify the position argument number of a term of the minimal and maximal value
of term;
\item \texttt{range(Min,Max)} extracts from the list of the complete annotation the sublist from position \texttt{Min} to
position \texttt{Max};
\end{itemize}
File Example \texttt{toto.seq}:
\begin{verbatim}
gb(3,5).
gb(7,9).
gb(8,11). % Overlap ;)
\end{verbatim}
Results of request are:
\begin{verbatim}
| ?- load_annotation_from_file(db,[],'toto.seq',R).
R = [0,0,1,1,1,0,1,1,1,1,1] ?
| ?- load_annotation_from_file(db,[in_db(c),out_db(nc)],'toto.seq',R).
R =  [nc,nc,c,c,c,nc,c,c,c,c,c]?
| ?- load_annotation_from_file(db,[range(3,7)],R).
R = [1,1,1,0,1] ?
| ?- load_annotation_from_file(db,[in_db(c),out_db(nc),range(8,16)],'toto.seq',R).
R =  [c,c,c,nc,nc,nc,nc,nc]?
\end{verbatim}
%
\index{get\_sequence\_from\_file$\slash$ 3}
\item \texttt{get\_sequence\_from\_file(++File,++Options,--Sequence)}:
Generate from \texttt{File} of data a sequence (read: a list) of data \texttt{Sequence}. This predicate is a more efficient implementation
of \verb+load_annotation_from_file\4+ with the type option \verb+sequence+ when several ranges of data have to be computed (option \verb+ranges+)

We assumed that data facts of \texttt{File} are composed of facts with the format: 
\begin{verbatim}
Term =.. [_Data_Functor,_Key,Range_Min,Range_Max,Data]
\end{verbatim} 
%
File Example \texttt{toto.seq}:
\begin{verbatim}
data(toto,1,10,[1,2,3,4,5,6,7,8,9,10]).
data(toto,11,20,[11,12,13,14,15,16,17,18,19,20]).
data(toto,21,30,[21,22,23,24,25,26,27,28,29,30]).
\end{verbatim}
Result of the request is:
\begin{verbatim}
| ?- get_data_from_file('toto.seq',[],R).
R = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,
                          21,22,23,24,25,26,27,28,29,30] ?
\end{verbatim}
%
Different options are available to specify the format of the data term:
\begin{itemize}
\item \verb+data_position(Pos)+ to specify an other position for the data; 
\item \verb+left_position(Left)+ to specify an other position for the left bound of the range that specifies the position of
           the data into the data file. When this left bound is not available, the keyword \verb+none+ for \verb+Pos+ can be used;
\item \verb+right_position(Right)+ to specify an other position for the right bound of the range that specifies the position of
           the data into the data file. When this right bound is not available, the keyword \verb+none+ for \verb+Pos+ can be used.
\end{itemize} 
%
File Example \texttt{toto2.seq}:
\begin{verbatim}
data(1,10,[1,2,3,4,5,6,7,8,9,10]).
data(11,20,[11,12,13,14,15,16,17,18,19,20]).
data(21,30,[21,22,23,24,25,26,27,28,29,30]).
\end{verbatim}
Result of the request is:
\begin{verbatim}
| ?- get_data_from_file('toto2.seq',
                       [left_position(1),
                        right_position(2),
                        data_position(3)],R).
R = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,
                          21,22,23,24,25,26,27,28,29,30] ?
\end{verbatim}
%
To ask for specific ranges of data, two options are available:
\begin{itemize}
\item \verb+range(Min,Max)+ computes the sequence of data between \verb+Min+ and \verb+Max+; 
\item \verb+ranges(List_Ranges)+ computes sequences of data for a list of ranges with a format \verb+[[Min1,Max1],[Min2,Max2],...]+.
Note that the ranges should be ordered, i.e \verb+Min1+ $\leq$ \verb+Min2+ must be satisfied.
\end{itemize}           
Result of the request is:
\begin{verbatim}
| ?- get_data_from_file('toto.seq',[range(5,10)],R).
R = [5,6,7,8,9,10] ?
| ?- get_data_from_file('toto.seq',[ranges([5,10],[5,8],[9,15])],R).
R = [[5,6,7,8,9,10],[5,6,7,8],[9,10,11,12,13,14,15]] ?
\end{verbatim}
\end{itemize}

\subsection{Saving information to files}

The io API also contains some predicates for saving sequences to a
file. 

\index{save\_annotation\_to\_sequence\_file$\slash$ 4}
\begin{itemize}
\item
  \texttt{save\_annotation\_to\_sequence\_file(+KeyIndex,+ChunkSize,+Annotation,+File)}: 
Saves the data in the list given by \texttt{Annotation} to the file
\texttt{File} in \emph{sequence} format which is number of Prolog facts, on
the form:
\begin{verbatim}
data(KeyIndex,1,5, [a,t,c,c,g]).
\end{verbatim}
The first argument \texttt{KeyIndex} is used as an identifier. \texttt{ChunkSize} is the
number of elements from \texttt{Annotation} to store with each
fact. The second and third argument of a stored fact, corresponds to
the start and end position in \texttt{Annotation}. The fourth
argument of the fact is a list containing the relevant elements of the
\texttt{Annotation} list. Note that if the the length of
\texttt{Annotation} is not a multiple of \texttt{ChunkSize}, then the
last fact stored will have a shorter range.
\end{itemize}

\subsection{Memory mapping of sequence files}

Some times it can be convenient load a sequence file into memory and then be able
to extract regions of the sequence on demand. The \texttt{io} API contains a method for
doing just this.

The predicate to map a file in the format \texttt{text(prolog(sequence(\_)))} into memory is
\begin{verbatim}
load_sequence(+SequenceID, +Filename)
\end{verbatim}

This will load the sequence from the file given by \texttt{Filename} and associate with the 
identifier \texttt{SequenceID}.


\begin{verbatim}
get_sequence_range(+SequenceID, +Min, +Max, -Data)
\end{verbatim}

The predicate 
\texttt{get\_sequence\_range/4}
can then be used to extract a part of the sequence. This is fairly efficient, but 
depends on the size of the data terms, $|t|$, in the file. The running time of the predicate
is bounded by $O(2 |t| \times n)$, where $n = \texttt{Max}-\texttt{Min}$.

\subsection{Splitting a Prolog file into multiple files}

When working with large data files, it can sometimes be practical to split a large 
file with Prolog facts into multiple files, each having a distinct subset of the facts 
in the original file.
The \texttt{io} API contains the predicate \texttt{split\_file/2} for doing this:

\begin{verbatim}
split_file(+InputFile,+FactsPerFile,
           +OutputFilePrefix, +OutputFileSuffix)
\end{verbatim}

The $n$ facts in the \texttt{InputFile} will be divided into $m = n / \texttt{FactsPerFile}$ output files. 

\section{The Stats API: \texttt{stats}}

In this module (\texttt{stats.pl}), several predicates are defined to automatically compute
frequencies, probabilities of occurrences of nucleotides, codons ... This computation
is based on a simple counting method given a simple input data. 

Variable \texttt{Data\_Type} is used to specify the type of the input data:
Data type available are:
\begin{itemize}
\item \texttt{nucleotide} where input data are composed of letter from $\{a,c,g,t\}$;
\item \texttt{codon} where a codon is represented by a list of three letters from $\{a,c,g,t\}$;
\item \texttt{amino\_acid} where input data are composed of letter from $\{a,c,d,e,f,g,h,$
$i,k,l,m,n,p,q,r,s,t,v,w,y\}$;
\item \texttt{length}. This type is used to compute frequencies and statistics about length of specific region of a genome. 
\end{itemize} 

Here is the description of main predicates of \texttt{stats.pl}
\begin{itemize}
\item stats(++Data\_Type,++Options,++Data,++Input\_Counting,--Result)\index{stats$\slash 5$} \\
\texttt{Data\_Type} setting define on which counting procedure is initialized. User must take care then
to give the right \texttt{Data}. For \{\texttt{nucleotide,codon,amino\_acid}\} data type, 
\texttt{Data} must be a Prolog list with the right element, For \texttt{length} data type,
\texttt{Data} must be a list of ranges represented by a list of two integer values ([Min,Max]).
Two options are available:
\begin{itemize}
\item \texttt{order(Num)} defines the size of the past stored to perform the counting
\item \texttt{past(List)} allows to give as input of the computation a previous past. This option is
useful to make connection between two counting computations.
\end{itemize}
\texttt{Input\_Counting} is used as well to perform a counting computation on an input data divided
into a set of lists. By default, counting computation is initialized when is a variable \texttt{Input\_Counting}.
However, the counting can restart from \texttt{Input\_Counting} if this variable is unified to
the result of a previous result. Finally, \texttt{Result} has the following format:
\begin{verbatim}
[(Past1,[(Elt1,Count11),(Elt2,Count12),...]), 
 (Past2,[(Elt1,Count21),(Elt2,Count22),...]),
 ...]
\end{verbatim}
For example let consider this following data:
\begin{verbatim}
data('U00096',1,5,[a,g,c,t,t]).
data('U00096',6,10,[c,c,c,c,c]).
\end{verbatim}
Here is the result of this following request
\begin{verbatim}
| ?- stats(nucleotide,[],[a,g,c,t,t],_,R).
R = [([],[(a,1),(c,1),(g,1),(t,2)])] ?
| ?- stats(nucleotide,[order(1)],[a,g,c,t,t],_,R).
R = [([a],[(a,0),(c,0),(g,1),(t,0)]),
     ([c],[(a,0),(c,0),(g,0),(t,1)]),
     ([g],[(a,0),(c,1),(g,0),(t,0)]),
     ([t],[(a,0),(c,0),(g,0),(t,1)])]?
| ?- stats(nucleotide,[order(2)],[a,g,c,t,t],_,R1),
     stats(nucleotide,[order(2),past([t,t])],[c,c,c,c,c],R1,R).
R = [([a,a],[(a,0),(c,0),(g,0),(t,0)]),
     ([a,c],[(a,0),(c,0),(g,0),(t,1)]),
     ([a,g],[(a,0),(c,1),(g,0),(t,0)]),
     ([a,t],[(a,0),(c,0),(g,0),(t,0)]),
     ([c,a],[(a,0),(c,0),(g,0),(t,0)]),
     ([c,c],[(a,0),(c,3),(g,0),(t,1)]),
     ([c,g],[(a,0),(c,1),(g,0),(t,0)]),
     ([c,t],[(a,0),(c,0),(g,0),(t,1)]),
     ([g,a],[(a,0),(c,0),(g,0),(t,0)]),
     ([g,c],[(a,0),(c,0),(g,0),(t,1)]),
     ([g,g],[(a,0),(c,1),(g,0),(t,0)]),
     ([g,t],[(a,0),(c,0),(g,0),(t,1)]),
     ([t,a],[(a,0),(c,0),(g,0),(t,0)]),
     ([t,c],[(a,0),(c,0),(g,0),(t,1)]),
     ([t,g],[(a,0),(c,0),(g,0),(t,0)]),
     ([t,t],[(a,0),(c,1),(g,0),(t,0)]),
     ]?
\end{verbatim}
\item stats(++Data\_Type,++Options,++Data,++Input\_Counting,--Past,--Result)\index{stats$\slash 6$}
\texttt{stats$\slash 6$} computes exactly the same counting. This predicate allows only to record
into \texttt{Past} the last past of the computing. This predicate is usefull to compute 
statistics on a series of data input. For example, this following request
\begin{verbatim}
| ? - stats(nucleotide,[order(2)],[a,g,c,t,t],_,Past,R1),
      stats(nucleotide,[order(2),past(Past)],[c,c,c,c,c],R1,Past2,R).
Past = [t,t],
Past2 = [c,c],
R = ... ?
\end{verbatim}     
can be used to obtain counting information on the previous data.
\item normalize(++Data\_Type,++List\_Counting,--Probabilities)\index{normalize$\slash 3$}
From the result of a counting procedure, \texttt{normalize$\slash 3$} modified \texttt{List\_Counting}
to compute domains and probabilities distributions. 
\end{itemize} 
For example, here is the result of several requests:
\begin{verbatim}
| ?- stats(nucleotide,[],[a,g,c,t,t],_,R),
     normalize(nucleotide,R,S).
S = [([],([a,c,g,t],[0.2,0.2,0.2,0.4]))]
| ?- stats(nucleotide,[order(1)],[a,g,c,t,t],_,R),
     normalize(nucleotide,R,S).
S = [([a],([a,c,g,t],[0,0,1,0])),
     ([c],([a,c,g,t],[0,0,0,1])),
     ([g],([a,c,g,t],[0,1,0,0])),
     ([t],([a,c,g,t],[0,0,0,1]))] ?
\end{verbatim}

To get a representation of the statistics where each count is represented
as a single fact, the predicate
\begin{verbatim}
build_stat_facts(+Stats,-StatsFacts)
\end{verbatim}
\noindent 
can be useful. For instance,
\begin{verbatim}
| ?- stats(nucleotide,[],[a,g,c,t,t],_,R), build_stat_facts(R,F).
R = [([],[(a,1),(c,1),(g,1),(t,2)])]
F = [stat([a],1),stat([c],1),stat([g],1),stat([t],2)] ?	
\end{verbatim}

\section{The \texttt{regex} API}
\label{sec:regex}

The \texttt{regex} API provides POSIX-like regular expressions for
matching Prolog strings and atoms. A regular expression is created
using
\begin{verbatim}
re_compile(+Regex, -CompiledRegex)
\end{verbatim}

The input argument \texttt{Regex} is an atom or a list of symbols
representing a particular regular expression. The output argument
\texttt{CompiledRegex} is used in subsequent matching with this 
regular expression.

Matching with a regular expression is then done using
\begin{verbatim}
re_match(+CompiledRegex,+String,-Matches)
\end{verbatim}

The goal \texttt{re\_match/3} is true whenever the
\texttt{CompiledRegex} matches the \texttt{String}. The \texttt{String} may be 
an atom or a list of symbols. If the goal is true, then
\texttt{Matches} is a list containing the matching parts of the \texttt{String} corresponding to
particular match groups (paranthesized sub-expressions) of the regular expression. 

Currently the regular expressions can be expressed using a
significant subset of the well-known POSIX regular expression
operators. The following operators are supported:

\begin{itemize}
\item \emph{Concatenation:} is expressed by the concatenation of two
  sub expressions. For instance, the regular expression  \texttt{ab}
  matches an \texttt{a} followed by a\texttt{b}.
\item \emph{Alternation:} is expressed with the vertical bar (\texttt{|}). For
  instance the expression \texttt{a|b} matches either \texttt{a} or \texttt{b}.
\item \emph{Repetition:} Repetition operators indicate the number of
  times a preceding regular expression may be matched. The following 
repetition operators are supported:
\begin{itemize}
\item \texttt{*} representing the Kleene star, meaning that the
  preceding expression is matched zero or more times.
\item \texttt{+} the preceding expression one or more times.
\item \texttt{?} The preceding expression zero times or one time.
\end{itemize}

Note that repetition binds stronger than alternation and alternation
binds stronger than concatenation. To enforce a different binding
order, enclosing sub-expressions in parentheses (which binds strongest)
are used.

Parenthesised sub-expressions can also be used to create \emph{match
  groups.} 
An outer-most paranthesized sub-expression,
  where the paranthesis are superflouos is interpreted as a match
  group. When an expression is matched, then the part of the string matched by the
  paranthesized expression is extracted. 
\end{itemize}

Additionally, ranges are supported by the regular expression syntax.
A range is expressed using square brackets. For instance,
\texttt{[a-z0-9]} is range expression which matches a lower case
alphanumeric character or a digit. 

\section{The \texttt{genecode} API}
\label{sec:genecode}

This API contains a set of genetic code tables. Each table defines
a relation between codons and amino acids. The main predicate of the API
is 
\begin{verbatim}
genecode(+Code, ?Codon, ?AminoAcid)
\end{verbatim}

\noindent
The argument code is an integer specifying the genetic code to
use. Currently, only genetic code \texttt{11} (bacterial) is
supported. \texttt{Codon} is a list of of three nucleotides symbols
from the alphabet \texttt{[a,g,c,t]}. The argument \texttt{AminoAcid}
is a symbol from the alphabet
\begin{verbatim}
[a,c,d,e,f,g,h,i,k,l,m,n,p,q,r,s,t,v,w,y,*]
\end{verbatim}

\noindent
Where all symbols except \texttt{*} represents an amino acid (the name
of which starts which that letter). The special symbol \texttt{*}
signifies a stop codon in the specified genetic code.

Other predicates in the genecode API include
\begin{verbatim}
genecode_start_codons(+GeneCode,-StartCodons)
\end{verbatim}

\noindent
The \texttt{genecode\_start\_codons/2} predicate unifies \texttt{StartCodons} with a list of all valid
start codons for the given \texttt{GeneCode}.

\begin{verbatim}
genecode_stop_codons(+GeneCode,-StopCodons)
\end{verbatim}

\noindent
The \texttt{genecode\_stop\_codons/2} predicate unifies \texttt{StopCodons} with a list of all valid
stop codons for the given \texttt{GeneCode}.

\section{The sequence API: \texttt{sequence}}

The \texttt{sequence} API is library containing predicates for 
doing common tasks with biological sequences.

\subsection{Complementing DNA sequences}

A complementary dna sequence can be achieved using the predicate

\begin{verbatim}
dna_seq_complement(+NucleotideSeq,-ComplNucleotideSeq)
\end{verbatim}

\noindent
When given the input sequence \texttt{NucleotideSeq} is a list of symbols from the alphabet
\texttt{[a,g,c,t]}, then \texttt{ComplNucleotideSeq} is unified to a list of complementary
symbols, e.g.

\begin{verbatim}
| ?- dna_seq_complement([a,g,a,c,t,a],X).
X = [t,c,t,g,a,t] ?
yes	
\end{verbatim}

Typically, when complementing a DNA sequence, we are actually interested in the \emph{reverse}
complement. To achieve this, use the built-in predicate \texttt{reverse/2} before \texttt{dna\_seq\_complement/2}.

\subsection{Translating a DNA sequence to amino acids}

The predicate, 

\begin{verbatim}
dna_amino_acid(+Genecode, ?DNA_Sequence,?AminoAcids)
\end{verbatim}

Translates a DNA sequence to a sequence of amino acids or vice versa; produces all possible DNA sequences for
a given amino acids sequence. \texttt{Genecode} is an integer for the genetic code to be used in the translation.
\texttt{DNA\_Sequence} is a list of symbols from the alphabet \texttt{[a,g,c,t]} and length of the list is expected
to be divisible by three. \texttt{AminoAcids} is a list of symbols from the alphabet,
\begin{verbatim}
[a,c,d,e,f,g,h,i,k,l,m,n,p,q,r,s,t,v,w,y,*].
\end{verbatim}

\chapter{Models}

Pre-defined models are introduced.  These models are used to build more complex models.

\section{Parsers of Biological Data}

To extract information from different Biological database, several parsers have been designed 
to parse report of analyses (Blast, Easygene and Genemark) and database (Genbank). 
These parsers generated a series of Prolog terms that can be used after that
input of different probabilistic models. \texttt{script\_parser.pl} collects different scripts to generate
different data files.

\subsection{Parser\_fna}

*.fna file of Genbank is composed of a complete genome in the FASTA format.
Parser\_fna permits to parse this *fna.file from Genbank and generate
list of terms. These terms store the genome into a Prolog list
composed of $\{a,c,g,t\}$. Two scripts are implemented:\\ 
\texttt{parser\_fna(++Name\_FNA\_File,++Name\_GBK\_File,++Options)}\index{parser\_fna$\slash$3} and \\
\texttt{parser\_fna(++Name\_FNA\_File,++Name\_GBK\_File,++Options,--OutputFile)}\index{parser\_fna$\slash$4}. \\
Note that *.gbk file is necessary as well. This file is used to automatically extract
genome information (Genbank key and size of genome).

Output format of the generated terms are:\\
\texttt{data(Genebank\_Key,Start,End,List\_of\_Data)}.
Option \texttt{list(Number)} can be used to divide the complete
genome into several lists with a length defined by the parameter
\texttt{Number}.
Example with the E.Coli K12 genome:
\begin{verbatim}
>gi|48994873|gb|U00096.2| Escherichia coli .....
AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGG.....
.....
\end{verbatim}
Result by default:
\begin{verbatim}
%>gi|48994873|gb|U00096.2| Escherichia coli ....
data('U00096',1,4639675,[a,g,c,t,t,t, ...]). 
\end{verbatim}
Result when \texttt{list(280)} option is used
\begin{verbatim}
%>gi|48994873|gb|U00096.2| Escherichia .....
data('U00096',1,280,[a,g,c,t,...]).
data('U00096',281,560,[c,c,c,...]).
....
\end{verbatim}

\subsection{Parser\_ptt}

A PTT file is the NCBI format for representation of a \emph{protein table}.
Typically, ptt files are composed of information about known or predicted
protein coding genes in a genome. Each such gene is represented
by a single line where tabulation separated fields represent various
properties of the gene such as the position, length, name and protein
product. The \texttt{parser\_ptt} model parses PTT files and generates
a Prolog term in the output file for each gene in the input (ptt) file.
We use the format identifier, \texttt{text(ptt)}, for PTT files, which
is also the input format of \texttt{parser\_ptt}. The output format is
\texttt{text(prolog(ranges(gene)))}. The model does not declare any options.

\medskip
\noindent
Consider the following extract of a PTT file:
\begin{verbatim}
Location	Strand	Length	PID	Gene	Synonym	Code	COG	Product
190..255	+	21	1786182	thrL	b0001	- - thr operon leader peptide
\end{verbatim}

The first line is just a header describing the names of the
individual fields, but the second is an entry for a particular gene. 
The corresponding Prolog term generated by the parser for this gene is
then
\begin{verbatim}
gb(190,255,'+',1,[
    gene_name(thrL),length(21),pid(1786182),
    synonym(b0001),code('-'),cog('-'),
    product('thr operon leader peptide')]
).
\end{verbatim}

\noindent
Additionaly, the file \texttt{\$SCRIPTS/script\_parser.pl} implements two helper
predicates to make it easy to use this parser:\\ 
\texttt{parser\_ptt(++Name\_PTT\_File)}\index{parser\_ptt$\slash$1} and \\
\texttt{parser\_ptt(++Name\_PTT\_File,,--OutputFile)}\index{parser\_ptt$\slash$2}.

\subsection{Parser\_Easygene}

This parser allows to generate from the \href{http://servers.binf.ku.dk/easygene/1.2/gff_output.html}{GFF format} 
of Easygene prediction several Prolog terms with the following format:
\texttt{eg(Left,Right,Dir,Frame,[])}.

Two scripts are implemented:\\ 
\texttt{parser\_easygene(++Report\_Name)}\index{parser\_easygene$\slash$1} and \\
\texttt{parser\_easygene(++Report\_Name,--OutputFile)}\index{parser\_easygene$\slash$2}.

\subsection{Parser\_Genemark}

This parser allows to generate from a report of Genemark.HMM 
of Easygene prediction several Prolog terms with the following format:
\texttt{gm(Left,Right,Dir,Frame,[])}. 
Genemark report of prediction coordinates is parsed.

Two scripts are implemented:\\ 
\texttt{parser\_genemark(++Report\_Name)}\index{parser\_genemark$\slash$1} and \\
\texttt{parser\_genemark(++Report\_Name,--OutputFile)}\index{parser\_genemark$\slash$2}.

\subsection{Parser\_Blast}

This parser translated into Prolog terms the XML report of Tblastn. The parser generates fact for
each hits detected of the XML report. 


\section{Models for measurement and statistical reports}

\subsection{accuracy\_report}

The model \texttt{accuracy\_report} can be used the produce a report of
various measures of the accuracy of particular gene predictions
compared with a golden standard such a genebank. 

To use the the model, you need to call
\texttt{get\_annotation\_file/4} with the following arguments,
\begin{verbatim}
get_annotation_file(accuracy_report,
		    [ReferenceFile,PredictionFile],
		    [
		     option(reference_functor,RefFunctor),
		     option(prediction_functor,PredFunctor),
		     option(start,StartPos),
		     option(end,EndPos)
		    ],
		    OutputFile),
\end{verbatim}

\texttt{ReferenceFile} must be the full path to a file with facts
representing the ``correct predictions''.  
\texttt{PredictionFile} must be the full path to a file with facts
representing the predictions. Both files must be a a \texttt{db} type 
format, with facts on the following form,
\begin{verbatim}
functor(To, From, Strand, ReadingFrame, Name).
\end{verbatim}

Each such fact represent a prediction in the \texttt{PredictionFile} or
correct gene in the in \texttt{ReferenceFile}. 
The \texttt{functor} is a any given functor, but the
\texttt{ReferenceFile} and the \texttt{PredictionFile} should use
different functors. The \emph{To} argument represents the position in
the genome where the prediction begins (inclusive) and the
\texttt{From} argument represents the end position of the prediction
\texttt{ReadingFrame} is a integer in the range $\{1,2,3\}$
\texttt{Strand} is either \texttt{+} for the forward strand or
    \texttt{-} for the reverse strand. 

\texttt{get\_annotation\_file} for the \texttt{accuracy\_report} model
must be called with four mandatory options:
\begin{itemize}
\item \texttt{reference\_functor}: The functor used in the \texttt{ReferenceFile}
\item \texttt{prediction\_functor}: The functor used in the
  \texttt{PredictionFile}
\item \texttt{start}: An integer corresponding to the beginning of the range on which accuracy
  should be measured.
\item \texttt{end}: An integer corresponding to the end of the range
  (inclusive) on which accuracy should be measured.
\end{itemize}

\subsection{The \texttt{range\_stats} model}

The \texttt{range\_stats} model calculates statistics for each gene or similar from a 
file in the format \texttt{text(prolog(ranges(gene)))}. The output file is also in the \texttt{text(prolog(ranges(gene)))} format, 
with an entry for each range in the original file, but with some statistics facts appended to the \texttt{ExtraList}.

The model takes two input files, 
\begin{itemize}
\item A \emph{ranges file} in \texttt{text(prolog(ranges(gene)))} format. 
\item A \emph{data file} in \texttt{text(prolog(sequence(gene)))} format.
\end{itemize}

The model can generate statistics basic nucleotide frequencies, amino acids frequencies and length.
The nucleotide sequence for the range is automatically extracted from the \emph{data file} and translated or 
reverse complemented as necessary. It is possible to adjust which kinds of statistics that should be generated by supplying the model
with relevant options:

\begin{itemize}
\item \texttt{amino\_acid\_stats}: Whether to add statistics based on amino acid frequency. Values are \texttt{yes} (default) or \texttt{no}.
\item \texttt{nucleotide\_stats}: Whether to add statistics based on nucleotide frequency.Values are \texttt{yes} (default) or \texttt{no}.
\item \texttt{length\_stats}: Whether to add statistics based on the length of the range.Values are \texttt{yes} (default) or \texttt{no}.
\item \texttt{max\_nucleotide\_order(N)}: Is an integer that determines the maximal order of nucleotide n-grams to calculate statistics for. Given this option the 
model will calculate statistics for nucleotide n-grams of size N+1 down to size 1. The default value is 1, which that single nucleotide frequency and di-nucleotide frequency will be calculated.
\item \texttt{max\_amino\_acid\_order(N)}: Is an integer that determines the maximal order of n-grams to calculate statistics for. Given this option the 
model will calculate statistics for amino acid n-grams of size N+1 down to size 1. The default value is 0 (e.g. only single amino acid frequencies).
\item \texttt{genecode}: An integer which identifies the gene code table to use when translating to amino acid sequence. Default is 11 (bacterial).
\end{itemize}

Depending the on the options for the model a subset of  the following facts are appended to the \texttt{ExtraList} of each gene in the output file:

\begin{itemize}
\item \texttt{nucleotide\_stats(L)} where \texttt{L} is list of elements of the type \texttt{stat(Seq,Freq)} and \texttt{Seq} is list of nucleotides signifying a particular n-gram (n being the length of list) and \texttt{Freq} is the frequency of the n-gram in the gene.
\item \texttt{amino\_acid\_stats(L)} where \texttt{L} is a list of elements of the type \texttt{stat(Seq,Freq)} and \texttt{Seq} is list of amino acid symbols signifying a particular n-gram (n being the length of list) and \texttt{Freq} is the frequency of the n-gram in the gene.
\item \texttt{normalized\_gene\_length(F)} where \texttt{F} is a number in the range $0\cdots1$ representing the proportion of the length of the range relative to the longest gene in the file. For instance, if the longest gene in the file is $2000$ nucleotides long and the gene in question is $1000$ nucleotides long, then the normalized gene length will be $1000/2000 = 0.5$.
\end{itemize}




\section{Prediction/Gene filter models}

Common for these models is that they all take files in the
\texttt{text(prolog(ranges(\_)))} format and produce output in 
the same format. Usually, the output will be a subset of the entries
from the input file.

\subsection{longest\_predication\_per\_stop\_codon}

Given an input file with gene predictions, this model selects for each
stop codon the longest matching prediction. Only the longest
prediction for each stop coden will be written to the output file.

For the goal \texttt{annotate/3}, the following files
and options are expected:
\begin{itemize}
\item Input files: \texttt{text(prolog(ranges(gene)))}
\item Output file: \texttt{text(prolog(ranges(gene)))}
\end{itemize}

The model only takes one option, \texttt{file\_functor}, which is 
used to set the functor to identify the gene predictions in the input
file. If the input file contains only facts with the same functor the 
default value \texttt{auto} can be used and the model will infer the 
functor automatically.

\subsection{best\_prediction\_per\_stop\_codon}

Given an input file with gene predictions this model selects, for each
stop codon, the prediction with the highest score and write such
predictions to the output file. The score is for each prediction is
assumed to be present the \texttt{Extra} list argument of the
prediction facts in the input file. 

For the goal \texttt{annotate/3}, the following files
and options are expected:
\begin{itemize}
\item Input files: \texttt{text(prolog(ranges(gene)))}
\item Output file: \texttt{text(prolog(ranges(gene)))}
\end{itemize}

The model only takes two option:

\begin{itemize} 
\item \texttt{file\_functor}: Is used to set the functor to
  identify the gene predictions in the input file. If the input file
  contains only facts with the same functor the default value
  \texttt{auto} can be used and the model will infer the functor
  automatically.
\item \texttt{score\_functor}: Is used to specify how the score is
  represented in the \texttt{Extra} list. For instance, if the Extra
  list looks like \verb|[...,score(0.75),..]|,  then the
  \texttt{score\_functor} option should be set to \texttt{score}.
  The argument of the score functor (\texttt{0.75} in the example)
  should be a number or at least something comparable with the
  standard less-than-or-equal-to Prolog operators.
\end{itemize}

\subsection{\texttt{gene\_filter}}

The \texttt{gene\_filter} model is a model that filters a set of genes
based on various matching criteria. The input to the model is 
a file in \texttt{text(prolog(ranges(gene)))} format containing the 
list of genes to be filtered and a file in
\texttt{text(prolog(sequence(dna)))} that includes the nucleotide
sequence for the entire genome to which the genes belong.
% FIXME: We should make the nucleotide sequence file optional.

The model supports filtering based on a wide range of criteria,
specified using the options given to the model. The model 
is invoked using \texttt{get\_annotation\_file/4.}

The options supported by the model are:
\begin{itemize}
\item \texttt{match\_frames}: A list of valid frames. Genes in other
  frames will be filtered. The list must be a subset of the \emph{default
    value}: \texttt{[1,2,3]}. 
\item \texttt{match\_strands}: A list of valid strands. Genes occuring
  an other strand will be filtered. The list must be a subset of the
  \emph{default value}: \texttt{['+','-']}.
\item \texttt{exact\_match\_extra\_fields}: A list of Prolog terms
  terms each of which must unify with an element of 
the \texttt{Extra} list of the gene terms. Genes which do not are filtered. 
\item  \texttt{exact\_no\_match\_extra\_fields}: A list of Prolog
  terms terms any of which \emph{may not} unify with any element of
  the \texttt{Extra} list of the gene terms. Genes which do are
  filtered.
\item \texttt{regex\_match\_extra\_fields}: A list of regular field
  names in the \texttt{Extra} list and regular expressions to match
  those fields.  For example, a regular expression matcher for the
  \texttt{name} field would be specified as \verb|name('^y.*$')|,
  here matching genes with a name starting with the letter y.
  The syntax of the regular expressions are as specified in section
  \ref{sec:regex}.
  Gene tems that do not match each of the specified regular
  expressions are filtered. 
\item \texttt{regex\_no\_match\_extra\_fields}: A list of field names
  in the extra and regular expressions to match those fields. If a
  gene is matched by any of these regular expression, it will be
  filtered.
\item \texttt{match\_protein\_coding}: Must be either \texttt{yes} or
 \texttt{no}. Default is \texttt{no}. 
If set to \texttt{yes}, this
  will filter gene terms which do not have a valid start and stop
  codon. The codon table to be used is specified using the the
  \texttt{genecode} option.
\item \texttt{genecode}: An integer specifying what genecode to use.
  Default is \texttt{11}, which is the bacterial gene code.  See
  \ref{sec:genecode} for a list of valid gene code tables. 
\item \texttt{invert\_results}: Must be either \texttt{yes} or
 \texttt{no}. Default is \texttt{no}. If set to \texttt{yes}, then
 only the otherwise non-filtered results are filtered.
\end{itemize}

\section{Model that integrate other programs}

\subsection{Genemark}

To be documented...

\subsection{Glimmer3}

To be documented...

\section{Various models}

\subsection{hard\_to\_find\_genes}

The model \texttt{hard\_to\_find\_genes} ranks a given set of genes
according to how many genefinders that find the gene.

The input to the model is a list of files, of which the first element
is taken to the \emph{golden standard} - a file containing a set of \emph{true} genes.
The rest of the $n$ files in the input file list are files that contain
gene predictions of various genefinders (one genefinder per input
file). All the files are expected to be in the
\texttt{text(prolog(ranges(gene)))} format.

For each gene in the \emph{golden standard} file, the model checks 
which of the gene finders predicts this gene. It writes each of these 
genes to the output file, but with facts added to the \texttt{Extra}
list. The added facts are 
\begin{itemize}
\item \texttt{found\_by\_genefinders(F)}: Where \texttt{F} is a list of $n$ entries
  containing
  \begin{itemize}
  \item \texttt{1} if the $n$th gene finder predicts the gene.
  \item \texttt{0} if the $n$th gene finder did not predict the gene.
  \end{itemize}
\item \texttt{gene\_finding\_difficulty\_score(S)}: Where \texttt{S}
  is a decimal number between zero and one representing the inverse of
  the proportion   of genefinders that predicts this gene. E.g. if it
  is zero, no gene finders predicts the gene, and if it is one, then
  all $n$ gene finders predicts the gene.
\end{itemize}

\noindent
The model take a number of options: 

\begin{itemize}
\item \texttt{start}: Is a positive integer indicating the start of
  the range in which to consider genes. Only genes starting/ending
  after this position are included in the output file. The default
  value \texttt{min} is taken to mean the start of the file,
  e.g. position 1.
\item \texttt{end}: Is a positive integer indicating the end of the
  range in which to consider genes. Only genes with a right border
  below this value included in the output file. The default value
  \texttt{max} is taken to mean the maximal position of any gene in the
  \emph{golden standard} file.
\item \texttt{gene\_match\_criteria}: Is used to determine what is
  required for a gene prediction to \emph{match} a gene. If the value
  is set to \texttt{start\_and\_stop} (default), then both start codon
  and stop codon needs to match. If the value is set to \texttt{stop}
  then only the stop codon needs to match.
\end{itemize}

\chapter{File formats}

The chapter documents the different types of file formats used in the
lost framework. The naming of file formats follow a simple scheme
using  nested Prolog functors where the outermost functor is the most
general and the innermost is the most specific description of the file
format. For instance, consider the naming for a DNA sequence expressed
as a Prolog file,
\begin{verbatim}
text(prolog(sequence(dna)))
\end{verbatim} 

The outermost functor \texttt{text} specifies that the file is a text
file, and the next functor \texttt{prolog} says that the text file
contains Prolog code. The next one, \texttt{sequence}, specifies the
type of data (sequence data) we expect to be expressed in the prolog
facts finally, the innermost functor \texttt{dna} specifies the type
of sequence that we are dealing with.

\section{\texttt{text(prolog(\_))}}

\texttt{text(prolog(\_))} formats contain Prolog facts. The functor and
arity of those facts cannot be determined by knowing that it is
\texttt{text(prolog(\_))}, but needs specification using further embbed
functors.

\subsection{\texttt{text(prolog(sequence(\_)))}}

This format should be specified for sequence data expressed as prolog
facts. For instance, a file of this format may contain facts like the
ones below, which specifies the alphabet, 
\begin{verbatim}
data(alphabet,1,10, [a,b,c,d,e,f,g,h,i,j]).
data(alphabet,11,20],[k,l,m,n,o,p,q,r,s,t]).
data(alphabet,21,27,[u,v,w,x,y,z]).
\end{verbatim}

\noindent
The form of these facts are, 
\begin{verbatim}
functor(Identifier,To,From,SequenceElementList).
\end{verbatim}

\noindent
The format does not dictate the \texttt{functor} of the facts
(e.g. \texttt{data}), nor the size of the data list in the fourth
argument. However, the range expressed by \texttt{To} and
\texttt{From} should correspond to the numer of elements
in \texttt{SequenceElementList}.

\subsubsection{\texttt{text(prolog(sequence(dna)))}}

Like the above format but restricts the alphabet of the data elements
in the \texttt{SequenceElementList} to the set \texttt{\{a,g,c,t\}}.

\subsubsection{\texttt{text(prolog(sequence(rna)))}}

Like the above format but restricts the alphabet of the data elements
in the \texttt{SequenceElementList} to the set \texttt{\{a,g,c,u\}}.

\subsubsection{\texttt{text(prolog(sequence(amino\_acids)))}}

Like the above format but restricts the alphabet of the data elements
in the \texttt{SequenceElementList} to the set
\texttt{\{a,c,d,e,f,g,h,i,k,l,m,n,p,q,r,s,t,v,w,y\}}.

\subsection{\texttt{text(prolog(ranges(\_)))}} 

The format consists of Prolog facts, each of which contain an
annotation for a particular range of some sequence

\begin{verbatim}
F =.. [ Functor, SequenceId, LeftEnd, RightEnd | _ ]
\end{verbatim}

The functor may vary depending on the type of annotation but is
expected to be same within a file. Similarly, \texttt{SequenceId} is an atom
which serves as sequence identifier. The next two arguments,
\texttt{LeftEnd} and \texttt{RightEnd} are positive integers which specifies 
the range relative to the sequence. Both are inclusive.  It must be
the case that $\texttt{LeftEnd} \le \texttt{RightEnd}$. 

\subsubsection{\texttt{text(prolog(ranges(gene)))}} 

This is a compatible subtype \texttt{text(prolog(ranges(\_)))}.
The format consists of Prolog facts, each of which contain an
gene annotation for a particular range of some DNA sequence
 (all facts refer to the same sequence).

The facts are on the form, 
\begin{verbatim}
functor(SequenceId,LeftEnd,RightEnd,Strand,Frame,ExtraList).
\end{verbatim}

The functor may vary depending on the type of annotation but is
expected to be same within a file. The first argument
\texttt{SequenceId} is a sequence identifer. Is is recommended that 
the Genbank accession id is used where possible.
The next two arguments,
\texttt{LeftEnd} and \texttt{RightEnd} are positive integers which specifies 
the range of the annotation relative to the DNA sequence. 
Both are inclusive.  It must be
the case that $\texttt{LeftEnd} \le \texttt{RightEnd}$. 
The
\texttt{Strand} argument is \texttt{'+'} for the forward strand
or\texttt{'-'} for the reverse strand. The \texttt{Frame} argument
is one of \texttt{\{1,2,3\}}. The final argument, \texttt{ExtraList}
is a list possibly containing extra information. Each element in the 
\texttt{ExtraList} is on the form \texttt{F =.. [ Key, Value ]} where
\texttt{Key} must be unique in the list. There are no restrictions on \texttt{Value}.


\subsection{\texttt{text(prolog(prism\_switches))}}

This is the format used by PRISM to save and load parameter files.

\subsection{\texttt{text(ptt)}}

TODO ptt files

\subsection{\texttt{text(easygene\_report)}}

TODO ptt files

\subsection{\texttt{text(fasta(SequenceType)}}

A sequence in FASTA format begins with a single-line description,
followed by lines of sequence data. The description line is
distinguished from the sequence data by a greater-than (">") symbol in
the first column. The word following the ">" symbol is the identifier
of the sequence, and the rest of the line is the description (both are
optional). There should be no space between the ">" and the first
letter of the identifier. It is recommended that all lines of text be
shorter than 80 characters. The sequence ends if another line starting
with a ">" appears; this indicates the start of another sequence. 

The format identifier \texttt{text(fasta(\_))} is used to refer to any
type of file in FASTA format, but we distinguish between different 
subtypes with \texttt{SequenceType}. A ground value for
\texttt{SequenceType} may be one of the following:

\begin{itemize}
\item \texttt{fasta}: Specifies generic fasta format. This is the same
  as specifying \texttt{text(fasta(\_))}.
\item \texttt{fna}: fasta nucleic acid. 
\item \texttt{ffn}: FASTA nucleotide coding regions. Contains coding
  regions for a genome.
\item \texttt{ffa}: fasta amino acid.
\end{itemize}

\chapter{Predicates listing}

\input{libraries} 

\chapter{Notes and stuff}

\section{Feature wish list}

\begin{itemize}

\item Division of models into models (probabilistic models) and nodes
  (which are just data processing).

\item 

\item Document gene database file format and make sure that all models
  adhere to this format.

\item Option, input and output formats for all models. (Matthieu, Christian)

\item Data outside git (Christian)

\item Models should \texttt{lost\_tmp\_directory} for intermediary
  files. 

\item Document all of undocumented models. (Matthieu, Christian)

\end{itemize}

Some things that we have discussed, but  decided not to do
\begin{itemize}
\item Do something to avoid multiple declaration of lost\_include\_api
 everywhere... (Matthieu).
\end{itemize}

\printindex

\end{document}
